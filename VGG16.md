- VGG网络图如下，本文要深入讲解的是很常用的VGG16网络。在看懂VGG16网络之前，先补一下卷积神经网络的知识，然后用代码实例来更好说明VGG16网络
https://pics5.baidu.com/feed/c2fdfc039245d6888f2a8c35134ecc18d31b248d.jpeg?token=9f27ce488fd6f3fdb238c6f94fe1dc14
### 图片数据如何输入？
- 彩色图像有RGB三个颜色通道，分别是红、绿、蓝三个通道，这三个通道的像素可以用二维数组来表示，其中像素值由0到255的数字来表示。比如一张160x60的彩色图片，可以用160*60*3的数组表示。
### 什么是卷积？
- 卷积过程是使用一个卷积核（如图中的Filter），在每层像素矩阵上不断按步长扫描下去，每次扫到的数值会和卷积核中对应位置的数进行相乘，然后相加求和，得到的值将会生成一个新的矩阵。
卷积核相当于卷积操作中的一个过滤器，用于提取我们图像的特征，特征提取完后会得到一个特征图。
- 卷积核的大小一般选择3x3和5x5，比较常用的是3x3，训练效果会更好。卷积核里面的每个值就是我们需要训练模型过程中的神经元参数（权重），开始会有随机的初始值，当训练网络时，网络会通过后向传播不断更新这些参数值，知道寻找到最佳的参数值。对于如何判断参数值的最佳，则是通过loss损失函数来评估。
- https://tukuimg.bdstatic.com/scrop/ae8a4d6f0ded77d731f179f361254db1.gif
### 什么是padding？
- 在进行卷积操作的过程中，处于中间位置的数值容易被进行多次的提取，但是边界数值的特征提取次数相对较少，为了能更好的把边界数值也利用上，所以给原始数据矩阵的四周都补上一层0，这就是padding操作。
- 在进行卷积操作之后维度会变少，得到的矩阵比原矩阵要小，不方便计算，原矩阵加上一层0的padding操作可以很好的解决该问题，卷积出来的矩阵和原矩阵尺寸一致。
### 什么是池化pooling?
- 池化操作相当于降维操作，有最大池化和平均池化，其中最大池化(max pooling)最为常用。
- 经过卷积操作后我们提取到的特征信息，相邻区域会有相似特征信息，这是可以相互替代的，如果全部保留这些特征信息会存在信息冗余，增加计算难度。
- 通过池化层会不断地减小数据的空间大小，参数的数量和计算量会有相应的下降，这在一定程度上控制了过拟合。
- https://ss1.baidu.com/6ONXsjip0QIZ8tyhnq/it/u=3880670482,34275673&fm=173&app=25&f=JPEG?w=480&h=242&s=DE04AE0E0770458A86686252030050F2
### 什么是Fletten？
- Flatten将池化后的数据拉开，变成一维向量来表示，方便输入到全连接网络。
### 什么是全连接层？
- 对n-1层和n层而言，n-1层的任意一个节点，都和第n层所有节点有连接。即第n层的每个节点在进行计算的时候，激活函数的输入是n-1层所有节点的加权。
https://pics5.baidu.com/feed/86d6277f9e2f070887621f3a51a8099fa901f23c.jpeg?token=30a8cc096c0598a7959998bde27addef
### 什么是Dropout？
- 在训练过程中，按照一定的比例将网络中的神经元进行丢弃，可以防止模型训练过拟合的情况。
### VGG16网络
https://pics7.baidu.com/feed/77c6a7efce1b9d166f0747f990e605898d546421.jpeg?token=a08388127ccd1d38524ed1cbe3db7cad
### VGG16网络代码实例讲解
https://ss2.baidu.com/6ONYsjip0QIZ8tyhnq/it/u=1882489676,154942204&fm=173&app=25&f=JPG?w=640&h=506&s=7B88782219FEE4CE0CD80CDA0300C0B3
https://pics0.baidu.com/feed/d009b3de9c82d158282b39b83e86a8debd3e42a5.png?token=4fb67fb11e231ba74bbcd934acbe9a5c
https://pics1.baidu.com/feed/4034970a304e251fbc5ef41c1f0a78117e3e533f.png?token=bafa62002fb45222c2941846d3fccfbf
https://pics7.baidu.com/feed/54fbb2fb43166d22ead60bf4f1afb8f19152d244.png?token=40e10916975fc03417232600457a084b
- 使用keras框架搭建的VGG16网络
- 开始输入（60,160,1）的图像数据，即宽为60，高度为160的单通道灰度图像，使用灰度图是为了加快模型的训练
- Conv2D(64, (3,3), name='conv1',padding='same', kernel_initializer='he_uniform')
- Conv2D卷积层的padding为"same"，即给图像矩阵四周都加上0。卷积核使用"he_uniform"，大小为3x3，卷积核个数为64，一个卷积核扫完图像矩阵数据后，生成一个新的矩阵，有64个卷积核就会生成64 层新的矩阵。
- BatchNormalization()(conv1)
- 使用BN层，加快模型的训练和防止模型训练过拟合
- Activation('relu')(bn1)
- 卷积后使用relu激活函数
- MaxPooling2D(pool_size=(2, 2), padding='same', name='pool3')(act7)
- 使用最大池化，池化的小矩阵是2x2，默认了也是2x2的步长。经过池化后，矩阵的长宽都降低一半，由64*160*60的数据变成64*80*30
- 其他同理，只是卷积核大小和卷积层个数做了修改。
- x = Flatten()(pool3)
- 做了13层卷积和相应的池化操作后，使用Flatten()，将数据拉平，变成一维向量
- x1 = Dense(4096)(x)bnx1 = BatchNormalization()(x1)actx1 = Activation('relu')(bnx1)drop9 = Dropout(0.4)(actx1)
- 最后做3层全连接层，前两个全连接层的神经元个数为4096，4096只是VGG16论文里提供的参考值，具体可以自己做测试修改。
- x = [Dense(10, activation='softmax', name='func%d'%(i+1))(x) for i in range(4)]

- VGG16网络里最后的全连接层是1000个神经元，如果你想用VGG16 给自己的数据作分类任务，这里就需要改成你预测的类别数。这个VGG16网络我是用于做4位数字验证码的识别，所以最后的全连接层我修改为创建4个全连接层,区分10类，分别识别4个字符。

- VGG网络图如下，本文要深入讲解的是很常用的VGG16网络。在看懂VGG16网络之前，先补一下卷积神经网络的知识，然后用代码实例来更好说明VGG16网络
https://pics5.baidu.com/feed/c2fdfc039245d6888f2a8c35134ecc18d31b248d.jpeg?token=9f27ce488fd6f3fdb238c6f94fe1dc14
### 图片数据如何输入？
- 彩色图像有RGB三个颜色通道，分别是红、绿、蓝三个通道，这三个通道的像素可以用二维数组来表示，其中像素值由0到255的数字来表示。比如一张160x60的彩色图片，可以用160*60*3的数组表示。
### 什么是卷积？
- 卷积过程是使用一个卷积核（如图中的Filter），在每层像素矩阵上不断按步长扫描下去，每次扫到的数值会和卷积核中对应位置的数进行相乘，然后相加求和，得到的值将会生成一个新的矩阵。
卷积核相当于卷积操作中的一个过滤器，用于提取我们图像的特征，特征提取完后会得到一个特征图。
- 卷积核的大小一般选择3x3和5x5，比较常用的是3x3，训练效果会更好。卷积核里面的每个值就是我们需要训练模型过程中的神经元参数（权重），开始会有随机的初始值，当训练网络时，网络会通过后向传播不断更新这些参数值，知道寻找到最佳的参数值。对于如何判断参数值的最佳，则是通过loss损失函数来评估。
- https://tukuimg.bdstatic.com/scrop/ae8a4d6f0ded77d731f179f361254db1.gif
### 什么是padding？
- 在进行卷积操作的过程中，处于中间位置的数值容易被进行多次的提取，但是边界数值的特征提取次数相对较少，为了能更好的把边界数值也利用上，所以给原始数据矩阵的四周都补上一层0，这就是padding操作。
- 在进行卷积操作之后维度会变少，得到的矩阵比原矩阵要小，不方便计算，原矩阵加上一层0的padding操作可以很好的解决该问题，卷积出来的矩阵和原矩阵尺寸一致。
### 什么是池化pooling?
- 池化操作相当于降维操作，有最大池化和平均池化，其中最大池化(max pooling)最为常用。
- 经过卷积操作后我们提取到的特征信息，相邻区域会有相似特征信息，这是可以相互替代的，如果全部保留这些特征信息会存在信息冗余，增加计算难度。
- 通过池化层会不断地减小数据的空间大小，参数的数量和计算量会有相应的下降，这在一定程度上控制了过拟合。
- https://ss1.baidu.com/6ONXsjip0QIZ8tyhnq/it/u=3880670482,34275673&fm=173&app=25&f=JPEG?w=480&h=242&s=DE04AE0E0770458A86686252030050F2
### 什么是Fletten？
- Flatten将池化后的数据拉开，变成一维向量来表示，方便输入到全连接网络。
### 什么是全连接层？
- 对n-1层和n层而言，n-1层的任意一个节点，都和第n层所有节点有连接。即第n层的每个节点在进行计算的时候，激活函数的输入是n-1层所有节点的加权。
https://pics5.baidu.com/feed/86d6277f9e2f070887621f3a51a8099fa901f23c.jpeg?token=30a8cc096c0598a7959998bde27addef
### 什么是Dropout？
- 在训练过程中，按照一定的比例将网络中的神经元进行丢弃，可以防止模型训练过拟合的情况。
### VGG16网络
https://pics7.baidu.com/feed/77c6a7efce1b9d166f0747f990e605898d546421.jpeg?token=a08388127ccd1d38524ed1cbe3db7cad
### VGG16网络代码实例讲解
https://ss2.baidu.com/6ONYsjip0QIZ8tyhnq/it/u=1882489676,154942204&fm=173&app=25&f=JPG?w=640&h=506&s=7B88782219FEE4CE0CD80CDA0300C0B3

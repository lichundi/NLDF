# Non-Local Deep Features for Salient Object Detection-用于显著目标检测得非局部深度特征
## 摘要
- 显著性检测旨在突出图像中最相关的对象。当突出目标在杂乱的背景上被描绘出来时，使用传统模型的方法会遇到困难，而深度神经网络则会受到过程复杂性和评估速度慢的影响。本文提出了一种简化的卷积神经网络，它通过一个多分辨率的4×5网格结构将局部和全局信息结合起来。我们没有像通常的情况那样用CRF或超混合来增强空间一致性，而是实现了一个受Mumford-Shah函数启发的损失函数，该函数惩罚边界上的错误。
## 1、引言
- 显著性检测的目的是模仿人类的视觉系统，自然地从图像的其余部分分离一个场景的主要对象。一个突出的物体通常被定义为一个区域，其视觉特征不同于图像的其余部分，其形状遵循一些先验标准[5]深度学习进入了显著性检测领域，并迅速确立了自己的事实基准。与传统的无监督方法相比，它们最大的优点是可以使用结合局部和深层特征的简单优化函数进行端对端训练。
- 在本文中，我们证明了通过简化的非局部深度特征(NLDF)模型可以实现最先进CNN模型的总体目标(增强预测显著性地图的空间相干性，并在优化中同时使用局部和全局特征)。受Mumford-Shah (MS)功能[35]的启发，贝叶斯损失加强了空间相干性。损失以交叉熵项和边界项的和表示。与传统的MS功能实现不同，我们使用由深度网络学习到的非局部特性，而不是原始的RGB颜色。此外，与直接最小化边界长度(如无监督的MS实现所做的那样)不同，我们使用预测和ground truth边界像素来最小化联合损失的交集。这个边界罚项被证明对我们的模型的性能有显著的贡献。
- 模型网络由卷积和反卷积块组成，在一个4×5网格(见图1)中，网格的每一列提取分辨率特定的特征。在每个分辨率轴上还使用局部对比度处理块，以提升局部对比度强的特征。得到的局部和全局特征被合并到一个分数处理块中，以输入分辨率的一半给出最终输出。
## 2、相关工作
## 3、提出的方法
### 3.1基于显著性检测的模型
- 突出区域检测和图像分割通常归结为对非凸能量函数的优化，该函数由一个数据项和一个正则项组成。
### 3.2网络架构
- 我们提供了一个深度卷积网络架构，其目标是学习鉴别显著性特征(我们的模型如图1所示)。正如在第2节中提到的，良好的显著性特征必须考虑到图像的局部和全局上下文，并结合不同分辨率的细节。为了实现这个目标，我们实现了一个新颖的网格状CNN网络，包含5列4行。在这里，每一列都针对特定于给定输入规模的特征提取。模型的输入I(左边)是一个352×352图像，输出(右边)是一个176×176 saliency map，我们使用双线性插值将其调整为352×352。
- 模型的第一行包含五个（CONV-1到CONV5）源自VGG-16的卷积块。如图1所示，这些卷积块包含步长为2的最大池化操作，对特征映射进行降采样，最后一行的最右边的卷积块计算特定于图像全局上下文的特征XG。
- 第二和第三行是一个由10个卷积块组成的集合，第2行从CONV-6到CONV-10，第3行从Contrast-1到Contrast-5。这些块的目的是计算特定于每个分辨率的特征(Xi)和对比特征(XC i)。对比特征捕捉每个特征相对于其局部邻域的差异，这些区域比它的邻域更亮或更暗。
- 最后一行是反卷积层，用于从11×11(右下)一直到176×176(左下)的特性映射。这些非池层是一种结合每个比例计算的特征图(Xi,XC i)的方法。左下的块构造了最终的局部特征映射XL。SCORE块有2个卷积层和一个softmax，通过融合局部(XL)和全局(XG)特征来计算显著性概率。表1给出了我们模型的更多细节
#### 3.2.1非局部特征提取
- 多尺度特征
- 反卷积特征
- 局部特征映射
- 获取全局上下文
### 3.3交叉熵损失函数
### 3.4IoU Boundary Loss
